# -*- coding: utf-8 -*-

import streamlit as st
import pandas as pd
from docxtpl import DocxTemplate
import google.generativeai as genai
import os
import re
import time
import zipfile
from io import BytesIO

# --- CONFIGURACIN DE LA PGINA DE STREAMLIT ---
st.set_page_config(
    page_title="Ensamblador de Fichas T茅cnicas con IA",
    page_icon="",
    layout="wide"
)

# --- FUNCIONES DE LGICA ---

def limpiar_html(texto_html):
    """Limpia etiquetas HTML de un texto."""
    if not isinstance(texto_html, str):
        return texto_html
    cleanr = re.compile('<.*?>')
    texto_limpio = re.sub(cleanr, '', texto_html)
    return texto_limpio

def setup_model(api_key):
    """Configura y retorna el cliente para el modelo Gemini."""
    try:
        genai.configure(api_key=api_key)
        generation_config = {
            "temperature": 0.6, "top_p": 1, "top_k": 1, "max_output_tokens": 8192
        }
        safety_settings = [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
        ]
        model = genai.GenerativeModel(
            model_name="gemini-1.5-pro-latest",
            generation_config=generation_config,
            safety_settings=safety_settings
        )
        return model
    except Exception as e:
        st.error(f"Error al configurar la API de Google: {e}")
        return None

# --- PROMPTS INTERNOS ---

PROMPT_ANALISIS = """
Act煤a como un experto en psicometr铆a y pedagog铆a. Tu misi贸n es deconstruir un 铆tem de evaluaci贸n.

--- INSUMOS DEL TEM ---
- Grado: {ItemGradoId}
- Competencia: {CompetenciaNombre}
- Evidencia: {EvidenciaNombre}
- Contexto: {ItemContexto}
- Enunciado: {ItemEnunciado}
- Opci贸n A: {OpcionA}
- Opci贸n B: {OpcionB}
- Opci贸n C: {OpcionC}
- Opci贸n D: {OpcionD}
- Respuesta Clave: {AlternativaClave}

--- INSTRUCCIONES ---

FASE 1: RUTA COGNITIVA
Describe, en un p谩rrafo continuo y de forma impersonal, el procedimiento mental que un estudiante debe ejecutar para llegar a la respuesta correcta.
1.  Genera la Ruta Cognitiva: Describe el paso a paso mental y l贸gico que un estudiante debe seguir para llegar a la respuesta correcta. Usa verbos que representen procesos cognitivos.
2.  Auto-Verificaci贸n: Revisa que la ruta se alinee con la Competencia ('{CompetenciaNombre}') y la Evidencia ('{EvidenciaNombre}').
3.  Justificaci贸n Final: El 煤ltimo paso debe justificar la elecci贸n de la respuesta correcta.

FASE 2: ANLISIS DE OPCIONES NO VLIDAS
- Para cada opci贸n incorrecta, identifica la naturaleza del error y explica el razonamiento fallido.
- Luego, explica el posible razonamiento que lleva al estudiante a cometer ese error.
- Finalmente, clarifica por qu茅 esa opci贸n es incorrecta en el contexto de la tarea evaluativa.

--- FORMATO DE SALIDA (REGLA CRTICA)---
Responde 煤nicamente con los dos t铆tulos siguientes, en este orden y sin a帽adir texto adicional.

Ruta Cognitiva Correcta:
[P谩rrafo continuo y detallado. Ejemplo: Para resolver correctamente este 铆tem, el estudiante primero debe [verbo cognitivo 1]... Luego, necesita [verbo cognitivo 2]... Este proceso le permite [verbo cognitivo 3]..., lo que finalmente lo lleva a concluir que la opci贸n {AlternativaClave} es la correcta porque [justificaci贸n final].]

An谩lisis de Opciones No V谩lidas:
- **Opci贸n [Letra del distractor]:** El estudiante podr铆a escoger esta opci贸n si comete un error de [naturaleza de la confusi贸n u error], lo que lo lleva a pensar que [razonamiento err贸neo]. Sin embargo, esto es incorrecto porque [raz贸n clara y concisa].
"""

PROMPT_SINTESIS = """
Act煤a como un experto en evaluaci贸n. Basado en la siguiente Ruta Cognitiva, redacta una 煤nica frase (m谩ximo 2 renglones) que resuma la habilidad principal que se est谩 evaluando.
Reglas:
1. Comienza obligatoriamente con "Este 铆tem eval煤a la capacidad del estudiante para...".
2. Describe procesos cognitivos gen茅ricos, no menciones detalles espec铆ficos del 铆tem.
3. Usa la taxonom铆a de referencia para que el lenguaje sea preciso.

RUTA COGNITIVA:
---
{ruta_cognitiva_texto}
---

TAXONOMA DE REFERENCIA:
- Competencia: {CompetenciaNombre}
- Evidencia de Aprendizaje: {EvidenciaNombre}

RESPUESTA:
"""

PROMPT_RECOMENDACIONES = """
Act煤a como un dise帽ador instruccional experto. Basado en la informaci贸n del 铆tem, genera tres recomendaciones distintas.

--- FORMATO DE SALIDA (REGLA CRTICA) ---
Usa obligatoriamente la siguiente estructura de encabezados.

RECOMENDACIN PARA FORTALECER
[Describe una actividad de aprendizaje creativa y no tradicional para un estudiante que respondi贸 incorrectamente, enfocada en remediar los errores conceptuales.]

RECOMENDACIN PARA AVANZAR
[Describe una actividad de profundizaci贸n o un desaf铆o para un estudiante que respondi贸 correctamente, para llevar su habilidad al siguiente nivel.]

OPORTUNIDAD DE MEJORA
[Proporciona un consejo pr谩ctico y directo basado en el apartado RECOMENDACIN PARA FORTALECER . Usa redacci贸n como "Se recomienda que...". Usa lenguaje impersonal]

--- INFORMACIN DEL TEM Y ANLISIS ---
- Qu茅 Eval煤a: {que_evalua_sintetizado}
- An谩lisis completo: {analisis_central_generado}
- Competencia: {CompetenciaNombre}
- Grado: {ItemGradoId}
"""

# --- FUNCIN PARA CONSTRUIR PROMPTS ---
def construir_prompt(fila, plantilla, **kwargs):
    fila = fila.fillna('')
    campos = {k: fila.get(k, '') for k in [
        'ItemContexto', 'ItemEnunciado', 'ComponenteNombre', 'CompetenciaNombre',
        'AfirmacionNombre', 'EvidenciaNombre', 'Tipologia Textual', 'ItemGradoId',
        'Analisis_Errores', 'AlternativaClave', 'OpcionA', 'OpcionB', 'OpcionC', 'OpcionD'
    ]}
    campos.update(kwargs)
    return plantilla.format(**campos)

# --- INTERFAZ PRINCIPAL DE STREAMLIT ---
st.title(" Ensamblador de Fichas T茅cnicas con IA")
st.markdown("Una aplicaci贸n para enriquecer datos pedag贸gicos y generar fichas personalizadas.")

if 'df_enriquecido' not in st.session_state: st.session_state.df_enriquecido = None
if 'zip_buffer' not in st.session_state: st.session_state.zip_buffer = None

st.sidebar.header(" Configuraci贸n Obligatoria")
api_key = st.sidebar.text_input("Ingresa tu Clave API de Google AI (Gemini)", type="password")

st.header("Paso 1: Carga tus Archivos")
col1, col2 = st.columns(2)
with col1: archivo_excel = st.file_uploader("Sube tu Excel con los datos base", type=["xlsx"])
with col2: archivo_plantilla = st.file_uploader("Sube tu Plantilla de Word", type=["docx"])

st.header("Paso 2: Enriquece tus Datos con IA")
if st.button(" Iniciar An谩lisis y Generaci贸n", disabled=(not api_key or not archivo_excel)):
    model = setup_model(api_key)
    if model:
        with st.spinner("Procesando archivo Excel y preparando datos..."):
            df = pd.read_excel(archivo_excel)
            for col in df.columns:
                if df[col].dtype == 'object': df[col] = df[col].apply(limpiar_html)
            
            columnas_nuevas = ["Que_Evalua", "Justificacion_Correcta", "Analisis_Distractores",
                               "Justificacion_A", "Justificacion_B", "Justificacion_C", "Justificacion_D",
                               "Recomendacion_Fortalecer", "Recomendacion_Avanzar", "oportunidad_de_mejora"]
            for col in columnas_nuevas:
                if col not in df.columns: df[col] = ""
            st.success("Datos limpios y listos.")

        progress_bar_main = st.progress(0, text="Iniciando Proceso...")
        total_filas = len(df)

        for i, fila in df.iterrows():
            item_id = fila.get('ItemId', i + 1)
            st.markdown(f"--- \n ### Procesando tem: **{item_id}**")
            progress_bar_main.progress((i + 1) / total_filas, text=f"Procesando 铆tem {i+1}/{total_filas}")

            with st.container(border=True):
                try:
                    # --- PASO 1: ANLISIS CENTRAL ---
                    st.write(f"**Paso 1/3:** Realizando an谩lisis central...")
                    prompt_paso1 = construir_prompt(fila, PROMPT_ANALISIS)
                    response_paso1 = model.generate_content(prompt_paso1)
                    analisis_central = response_paso1.text.strip()
                    time.sleep(1.5)

                    header_correcta = "Ruta Cognitiva Correcta:"
                    header_distractores = "An谩lisis de Opciones No V谩lidas:"
                    idx_distractores = analisis_central.find(header_distractores)

                    if idx_distractores != -1:
                        ruta_cognitiva = analisis_central[len(header_correcta):idx_distractores].strip()
                        analisis_distractores_bloque = analisis_central[idx_distractores + len(header_distractores):].strip()
                        
                        df.loc[i, "Justificacion_Correcta"] = ruta_cognitiva
                        df.loc[i, "Analisis_Distractores"] = analisis_distractores_bloque

                        clave_correcta = str(fila.get('AlternativaClave', '')).strip().upper()
                        opciones = ['A', 'B', 'C', 'D']
                        
                        for opt in opciones:
                            if opt == clave_correcta:
                                df.loc[i, f"Justificacion_{opt}"] = ruta_cognitiva
                            else:
                                # L贸gica de separaci贸n mejorada
                                pattern = re.compile(rf"-\s*\*\*\s*Opci贸n\s*{opt}:\s*\*\*(.*?)(?=-\s*\*\*Opci贸n|\Z)", re.DOTALL | re.IGNORECASE)
                                match = pattern.search(analisis_distractores_bloque)
                                df.loc[i, f"Justificacion_{opt}"] = match.group(1).strip() if match else "An谩lisis del distractor no encontrado."
                    else:
                        df.loc[i, "Justificacion_Correcta"] = analisis_central
                        df.loc[i, "Analisis_Distractores"] = "Error al parsear distractores"

                    # --- PASO 2: SNTESIS DEL "QU EVALA" ---
                    st.write(f"**Paso 2/3:** Sintetizando 'Qu茅 Eval煤a'...")
                    prompt_paso2 = construir_prompt(fila, PROMPT_SINTESIS, ruta_cognitiva_texto=df.loc[i, "Justificacion_Correcta"])
                    response_paso2 = model.generate_content(prompt_paso2)
                    df.loc[i, "Que_Evalua"] = response_paso2.text.strip()
                    time.sleep(1.5)
                    
                    # --- PASO 3: GENERACIN DE RECOMENDACIONES (3 en 1) ---
                    st.write(f"**Paso 3/3:** Generando recomendaciones pedag贸gicas...")
                    prompt_paso3 = construir_prompt(fila, PROMPT_RECOMENDACIONES, que_evalua_sintetizado=df.loc[i, "Que_Evalua"], analisis_central_generado=analisis_central)
                    response_paso3 = model.generate_content(prompt_paso3)
                    recomendaciones = response_paso3.text.strip()
                    
                    # L贸gica para separar las 3 recomendaciones
                    fortalecer_match = re.search(r'RECOMENDACIN PARA FORTALECER(.*?)RECOMENDACIN PARA AVANZAR', recomendaciones, re.DOTALL | re.IGNORECASE)
                    avanzar_match = re.search(r'RECOMENDACIN PARA AVANZAR(.*?)OPORTUNIDAD DE MEJORA', recomendaciones, re.DOTALL | re.IGNORECASE)
                    oportunidad_match = re.search(r'OPORTUNIDAD DE MEJORA(.*?)$', recomendaciones, re.DOTALL | re.IGNORECASE)

                    df.loc[i, "Recomendacion_Fortalecer"] = fortalecer_match.group(1).strip() if fortalecer_match else "No generada."
                    df.loc[i, "Recomendacion_Avanzar"] = avanzar_match.group(1).strip() if avanzar_match else "No generada."
                    df.loc[i, "oportunidad_de_mejora"] = oportunidad_match.group(1).strip() if oportunidad_match else "No generada."

                    st.success(f"tem {item_id} procesado con 茅xito.")

                except Exception as e:
                    st.error(f"Ocurri贸 un error procesando el 铆tem {item_id}: {e}")
                    for col in columnas_nuevas: df.loc[i, col] = f"ERROR: {e}"
        
        progress_bar_main.progress(1.0, text="隆Proceso completado!")
        st.session_state.df_enriquecido = df
        st.balloons()

# --- PASO 3: Vista Previa y Descarga de Excel ---
if st.session_state.df_enriquecido is not None:
    st.header("Paso 3: Verifica y Descarga los Datos Enriquecidos")
    st.dataframe(st.session_state.df_enriquecido.head())
    output_excel = BytesIO()
    with pd.ExcelWriter(output_excel, engine='openpyxl') as writer:
        st.session_state.df_enriquecido.to_excel(writer, index=False, sheet_name='Datos Enriquecidos')
    output_excel.seek(0)
    st.download_button(
        label=" Descargar Excel Enriquecido", data=output_excel,
        file_name="excel_enriquecido_con_ia.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

# --- PASO 4: Ensamblaje de Fichas ---
if st.session_state.df_enriquecido is not None and archivo_plantilla is not None:
    st.header("Paso 4: Ensambla las Fichas T茅cnicas")
    columna_nombre_archivo = st.text_input("Escribe el nombre de la columna para nombrar los archivos (ej. ItemId)", value="ItemId")
    if st.button(" Ensamblar Fichas T茅cnicas", type="primary"):
        df_final = st.session_state.df_enriquecido
        if columna_nombre_archivo not in df_final.columns:
            st.error(f"La columna '{columna_nombre_archivo}' no existe en el Excel. Elige una de: {', '.join(df_final.columns)}")
        else:
            with st.spinner("Ensamblando todas las fichas en un archivo .zip..."):
                plantilla_bytes = BytesIO(archivo_plantilla.getvalue())
                zip_buffer = BytesIO()
                with zipfile.ZipFile(zip_buffer, "a", zipfile.ZIP_DEFLATED, False) as zip_file:
                    total_docs = len(df_final)
                    progress_bar_zip = st.progress(0, text="Iniciando ensamblaje...")
                    for i, fila in df_final.iterrows():
                        plantilla_bytes.seek(0)
                        doc = DocxTemplate(plantilla_bytes)
                        contexto = fila.to_dict()
                        contexto_limpio = {k: (v if pd.notna(v) else "") for k, v in contexto.items()}
                        doc.render(contexto_limpio)
                        doc_buffer = BytesIO()
                        doc.save(doc_buffer)
                        doc_buffer.seek(0)
                        nombre_base = str(fila.get(columna_nombre_archivo, f"ficha_{i+1}")).replace('/', '_').replace('\\', '_')
                        zip_file.writestr(f"{nombre_base}.docx", doc_buffer.getvalue())
                        progress_bar_zip.progress((i + 1) / total_docs, text=f"A帽adiendo ficha {i+1}/{total_docs} al .zip")
                st.session_state.zip_buffer = zip_buffer
                st.success("隆Ensamblaje completado!")

# --- PASO 5: Descarga Final del ZIP ---
if st.session_state.zip_buffer:
    st.header("Paso 5: Descarga el Resultado Final")
    st.download_button(
        label=" Descargar TODAS las fichas (.zip)",
        data=st.session_state.zip_buffer.getvalue(),
        file_name="fichas_tecnicas_generadas.zip",
        mime="application/zip"
    )
